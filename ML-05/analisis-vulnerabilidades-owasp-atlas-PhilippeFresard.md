# Vulnerabilidad: Model Theft

La vulnerabilidad **Model Theft** identificada por OWASP ocurre cuando un atacante logra robar o replicar un modelo de *machine learning*, accediendo a sus parámetros internos o copiando su funcionamiento a través de múltiples consultas (*model extraction*). Este tipo de ataque afecta directamente la propiedad intelectual del modelo y puede exponer datos sensibles utilizados en su entrenamiento. Para reducir el riesgo, OWASP propone controles como **cifrado**, **restricción de accesos**, **watermarking** y **monitoreo continuo del uso del modelo**.

Al observar la matriz de **MITRE ATLAS**, el concepto de Model Theft de OWASP se relaciona con varias técnicas de las tácticas **Exfiltration** y **AI Attack Staging**. En particular, la técnica **Exfiltration via AI Inference API** refleja claramente el escenario descrito por OWASP: un atacante utiliza la interfaz de consulta del modelo para obtener información suficiente que le permita reconstruirlo, correspondiendo directamente a los ataques de extracción mediante consultas.

De forma complementaria, la técnica **Exfiltration via Cyber Means** también es análoga, ya que contempla el robo directo de archivos o parámetros del modelo desde el sistema que lo aloja, coincidiendo con la dimensión de acceso no autorizado que OWASP señala. Además, en la táctica **AI Attack Staging**, la técnica **Create Proxy AI Model** conecta con el mismo problema, describiendo la creación de un modelo sustituto que imita el comportamiento del original, justamente el objetivo de un ataque de model theft.
