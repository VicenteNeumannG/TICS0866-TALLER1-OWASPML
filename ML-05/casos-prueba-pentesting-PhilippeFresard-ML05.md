#Caso 1

# Caso de Prueba: ML05:2023 – Model Theft

**ID:** ML05-01  

**Tipo:** ATAQUE  
**Vulnerabilidad:** ML05:2023 – Model Theft  
**Descripción:** Evaluar la resistencia del sistema *Intrusion.Aware* frente a intentos de extracción del modelo de detección mediante consultas masivas y análisis de salidas para replicar su comportamiento.  
**Entrada:** [Consultas automatizadas al motor de predicción variando características del dataset UNSW-NB15]  
**Salida Esperada:** [El modelo se mantiene protegido, limitando consultas o entregando respuestas sin exponer reglas internas]  
**Salida Real:** [RESULTADO OBTENIDO]  
**Estado:** [PENDIENTE/COMPLETADO/FALLIDO]  
**Severidad:** [ALTA]  

---
## Precondiciones
- Acceso a la API o al motor *PredictionEngine* de Intrusion.Aware  
- Conocimiento de técnicas de *model extraction* (Knockoff Nets, Path finding en árboles de decisión, etc.)  
- Scripts para automatizar consultas y registrar salidas  
---

## Procedimiento paso a paso
1. Identificar el endpoint o interfaz donde se consultan predicciones.  
2. Diseñar un conjunto de entradas variadas basadas en el dataset UNSW-NB15.  
3. Automatizar el envío de miles de consultas para mapear respuestas del modelo.  
4. Usar técnicas de aprendizaje inverso (*Knockoff Nets*, *Tree Approximation*) para reconstruir un modelo sustituto.  
5. Comparar el rendimiento del modelo clonado con el original (precisión, recall).  
6. Evaluar impacto: capacidad de evadir reglas, pérdida de confidencialidad del modelo.  
7. Documentar halla

# Caso 2

# Caso de Prueba: ML05:2023 – Model Theft

**ID:** ML05-02  
**Tipo:** ATAQUE  
**Vulnerabilidad:** ML05:2023 – Model Theft  
**Descripción:** Evaluar si un atacante puede extraer el modelo de clasificación multi-clase de *Intrusion.Aware* (capaz de detectar 9 tipos de ataques) aprovechando consultas limitadas pero estratégicamente diseñadas, para construir un modelo sustituto que imite el comportamiento del original.  
**Entrada:** [Conjunto reducido de consultas optimizadas (Active Learning) al clasificador multi-clase]  
**Salida Esperada:** [El modelo mantiene su confidencialidad; las respuestas no permiten replicar su lógica interna]  
**Salida Real:** [RESULTADO OBTENIDO]  
**Estado:** [PENDIENTE/COMPLETADO/FALLIDO]  
**Severidad:** [ALTA]  

---

## Precondiciones
- Acceso indirecto al clasificador multi-clase a través de la API del sistema.  
- Conocimiento de técnicas de *query synthesis* y *active learning*.  
- Capacidad para recolectar y etiquetar resultados de predicciones.  

## Procedimiento paso a paso
1. Analizar el endpoint del clasificador multi-clase de *Intrusion.Aware*.  
2. Diseñar consultas iniciales usando entradas base del dataset UNSW-NB15.  
3. Aplicar *active learning* para seleccionar nuevas consultas que maximicen la información obtenida.  
4. Recopilar respuestas del modelo para cada consulta (9 clases posibles).  
5. Entrenar un modelo sustituto (Random Forest o Red Neuronal ligera) con los datos recolectados.  
6. Validar la precisión del modelo clonado contra nuevas entradas.  
7. Documentar resultados y proponer contramedidas.  
