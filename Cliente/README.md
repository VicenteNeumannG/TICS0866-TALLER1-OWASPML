# üõ°Ô∏è Intrusion.Aware v0.4.0
## Sistema Inteligente de Detecci√≥n de Ataques Cibern√©ticos

**Proyecto FONDEF-ANID - Universidad Adolfo Ib√°√±ez**  
**Curso:** TICS00866 - Auditor√≠a y Defensa en Sistemas de Inteligencia Artificial

---

## üéØ **¬øQu√© es Intrusion.Aware?**

**Intrusion.Aware** es un sistema inteligente de detecci√≥n de ataques cibern√©ticos que utiliza **Machine Learning (ML)** para proteger computadoras y redes de organizaciones. Es como tener un "guardi√°n digital" que vigila constantemente y detecta cuando alguien est√° intentando atacar tu sistema.

### **üè¢ Prop√≥sito Principal:**
- Ayudar a **analistas de seguridad** (SOCs) que protegen organizaciones
- Asistir a **administradores de TI** que gestionan la infraestructura tecnol√≥gica
- Proteger **empresas** que necesitan resguardar sus datos y sistemas

---

## üß¨ **IA Security Village: El Juego de Roles**

### **üé≠ Inspiraci√≥n: Biohacking Village de DEFCON**

Inspirados en el **Biohacking Village de DEFCON**, donde empresas como **Agfa**, **Medtronic**, **Siemens Healthineers** y **Boston Scientific** llevan sus dispositivos m√©dicos para ser evaluados por hackers √©ticos, nuestro taller simula un entorno similar:

- **üè¢ "Empresa":** Universidad Adolfo Ib√°√±ez presenta su sistema Intrusion.Aware
- **üîç "Hackers √âticos":** Estudiantes del curso TICS00866
- **üéØ "Objetivo":** Encontrar vulnerabilidades antes del lanzamiento al mercado
- **üèÜ "Premio":** Contribuir a la seguridad de sistemas de IA para la sociedad

### **üéÆ ¬øPor qu√© es Importante este Juego de Roles?**

As√≠ como los dispositivos m√©dicos pueden causar da√±o f√≠sico si son vulnerables, los **sistemas de IA** pueden causar da√±o social, econ√≥mico y de privacidad si no son seguros. Nuestro taller sigue la misma filosof√≠a:

- **üîç Detecci√≥n Temprana:** Encontrar vulnerabilidades antes del despliegue
- **üõ°Ô∏è Protecci√≥n Social:** Evitar que sistemas inseguros afecten a la sociedad
- **ü§ù Colaboraci√≥n:** Trabajar con desarrolladores para mejorar la seguridad
- **üìö Educaci√≥n:** Crear conciencia sobre vulnerabilidades en IA

**Referencias:**
- [DEFCON Biohacking Village 2024 - Deloitte](https://www.deloitte.com/hu/en/services/risk-advisory/perspectives/defcon-biohacking-village-2024.html)
- [OWASP Machine Learning Security Top 10](https://github.com/owasp/www-project-machine-learning-security-top-10)
- [Biohacking Village Official](https://www.villageb.io/)

---

## üîß **¬øC√≥mo Funciona Intrusion.Aware?**

### **1. Monitoreo Continuo** üîç
- Se instala en cada computadora o punto de red que quieres proteger
- Constantemente "escucha" todo el tr√°fico de red que pasa por el dispositivo
- Es como tener una c√°mara de seguridad que vigila el tr√°fico digital

### **2. Detecci√≥n Inteligente con IA** ü§ñ
- Cuando detecta actividad sospechosa, la IA analiza si es un ataque real
- Utiliza **dos modelos de IA**:
  - **Primer modelo**: ¬øEs esto un ataque o tr√°fico normal? (98% de precisi√≥n)
  - **Segundo modelo**: Si es ataque, ¬øqu√© tipo de ataque es? (9 tipos diferentes)

### **3. Explicabilidad de Decisiones** üí°
- **Decision Trees** (√°rboles de decisi√≥n) para explicaci√≥n intr√≠nseca
- **SHAP** y **LIME** para explicaciones post-hoc
- **UXAI.design** para interfaces centradas en el usuario

---

## üß† **Arquitectura de Modelos y Explicabilidad**

### **Modelos de Machine Learning**

#### **Versi√≥n 0.4.0 (Actual) - Decision Trees**
- **Ventaja**: Interpretabilidad intr√≠nseca, reglas expl√≠citas
- **Uso**: Explicabilidad local para cada detecci√≥n individual
- **Ejemplo de regla**: `SI service=HTTP AND sbytes>1000 AND dur<30 ENTONCES FUZZER`
- **Beneficio**: Los analistas SOC pueden entender y validar cada decisi√≥n
- **Precisi√≥n actual**: ~85% (mejorable en futuras versiones)

#### **Versi√≥n 0.5.0+ (Planificado) - Enfoque H√≠brido**
- **XGBoost**: Mayor precisi√≥n (98% esperado)
- **SHAP**: Explicar√° contribuciones de caracter√≠sticas en modelos complejos
- **Beneficio**: Mejor de ambos mundos - precisi√≥n alta + explicabilidad completa

### **Explicabilidad en Intrusion.Aware**

#### **Modelos Interpretables por Naturaleza (Intrinsic Interpretability)**
Los **Decision Trees** son modelos **intr√≠nsecamente interpretables** porque:
- **Estructura transparente**: Cada decisi√≥n es visible y explicable
- **Reglas expl√≠citas**: Generan reglas del tipo "SI condici√≥n ENTONCES resultado"
- **Trazabilidad completa**: Se puede seguir el camino de decisi√≥n desde la ra√≠z hasta la hoja
- **Sin necesidad de m√©todos externos**: La explicaci√≥n est√° en la estructura misma del modelo

**Ejemplo de regla interpretable:**
```
SI service = HTTP AND sbytes > 1000 AND ct_flw_http_mthd > 3 AND dur < 30 
ENTONCES FUZZER
```

#### **Enfoque H√≠brido Implementado**
```
Tr√°fico de Red ‚Üí Argus (Extracci√≥n) ‚Üí 49 Caracter√≠sticas UNSW-NB15
    ‚Üì
XGBoost (Detecci√≥n Inicial) ‚Üí Decision Tree (Explicaci√≥n Local) ‚Üí SHAP (Contexto Global)
    ‚Üì
UXAI.design Framework ‚Üí Interfaces Explicables ‚Üí Decisi√≥n Final
```

---
## üèóÔ∏è **Arquitectura del Sistema**

### **Componentes Principales:**

#### **üîç Detector de Intrusiones**
- **Modelo ML**: Decision Trees (v0.4.0)
- **Dataset**: UNSW-NB15 (49 caracter√≠sticas)
- **Precisi√≥n**: 98% en detecci√≥n binaria

#### **üìä Sistema de Explicabilidad**
- **Intr√≠nseca**: Decision Trees interpretables
- **Post-hoc**: SHAP, LIME
- **UXAI**: Interfaces centradas en explicaci√≥n

#### **üîó Ledger Distribuido (Neuroledger)**
- **Identidad Digital**: Gesti√≥n de usuarios y permisos
- **Contratos Inteligentes**: T√©rminos de acceso a datos
- **Auditor√≠a**: Registro inmutable de actividades

#### **üì± Aplicaci√≥n M√≥vil**
- **Notificaciones**: Alertas en tiempo real
- **Dashboard**: Visualizaci√≥n de ataques detectados
- **Respuesta**: Acciones de mitigaci√≥n

### **Flujo de Procesamiento:**
```
Tr√°fico de Red ‚Üí Argus (Extracci√≥n) ‚Üí 49 Caracter√≠sticas UNSW-NB15 ‚Üí Decision Tree ‚Üí Decisi√≥n + Explicaci√≥n
```

---

## üîÑ **Funcionalidades Principales**

### **1. Monitoreo**
- **NLSensor**: Componente que se despliega en dispositivos a monitorear
- **Sniffer local**: Genera archivos pcap del tr√°fico de red
- **Preprocesador**: Extrae caracter√≠sticas usando Argus
- **PredictionEngine**: Motor de decisi√≥n con modelos ML

### **2. An√°lisis**
- **Interfaces explicables**: Centradas en el usuario usando UXAI.design
- **SHAP**: Identifica caracter√≠sticas m√°s relevantes
- **Reclasificaci√≥n**: Los analistas pueden corregir etiquetas
- **Dashboard**: Visualizaci√≥n de ataques detectados

### **3. Respuesta**
- **Recomendaciones**: Basadas en MITRE ATT&CK
- **Acciones autom√°ticas**: Bloqueos de IP o puertos
- **Aprobaci√≥n humana**: Human-in-the-loop para acciones cr√≠ticas
- **Extensibilidad**: Sistema MAPE-K para respuesta aut√≥noma

### **4. Reporte**
- **Registros inmutables**: Usando Neuroledger
- **Dashboards**: Filtrado y agrupaci√≥n de ataques
- **Auditor√≠a**: Trazabilidad completa de acciones
- **Exportaci√≥n**: Datos para an√°lisis externo

---

## üîí **Seguridad y Privacidad**

### **Medidas de Seguridad:**
- **Encriptaci√≥n** de datos en tr√°nsito y reposo
- **Autenticaci√≥n** multifactor
- **Autorizaci√≥n** basada en roles
- **Auditor√≠a** completa de actividades

### **Privacidad:**
- **Derecho al olvido** (GDPR compliance)
- **Contratos inteligentes** revocables
- **Anonimizaci√≥n** de datos sensibles
- **Control granular** de acceso
- **Procesamiento local**: Todo se hace en la organizaci√≥n, no en la nube

### **Ledger Distribuido Privado (Neuroledger)**
- Cada dispositivo tiene una "identidad digital" √∫nica
- Los contratos de monitoreo son inteligentes y verificables
- Registros inmutables de todas las acciones
- Cumple con GDPR (derecho al olvido)

---

## üéØ **Casos de Uso**

### **Para Analistas SOC:**
- Detecci√≥n autom√°tica de ataques
- Explicaciones claras de decisiones
- Dashboard de monitoreo en tiempo real
- Recomendaciones de mitigaci√≥n

### **Para Administradores TI:**
- Monitoreo de infraestructura completa
- Respuesta autom√°tica a amenazas
- Auditor√≠a de actividades de seguridad
- Gesti√≥n de permisos y acceso

### **Para Organizaciones:**
- Protecci√≥n proactiva contra ataques
- Cumplimiento con regulaciones
- Reducci√≥n de falsos positivos
- Mejora continua de seguridad

---

## üöÄ **Estado del Proyecto**

### **Versi√≥n Actual: v0.4.0**
- ‚úÖ **Decision Trees** implementados y funcionando
- ‚úÖ **Detecci√≥n binaria** con 98% de precisi√≥n
- ‚úÖ **Clasificaci√≥n multi-clase** de 9 tipos de ataques
- ‚úÖ **Sistema de explicabilidad** h√≠brido implementado
- ‚úÖ **Aplicaci√≥n m√≥vil** b√°sica desarrollada

### **Pr√≥ximas Versiones:**
- üîÑ **v0.5.0**: Implementaci√≥n de XGBoost + SHAP
- üîÑ **v0.6.0**: Mejoras en explicabilidad con UXAI.design
- üîÑ **v1.0.0**: Versi√≥n de producci√≥n completa

## üìà **M√©tricas de Rendimiento**

### **M√©tricas de Detecci√≥n:**
- **Tasa de Falsos Positivos**: < 2%
- **Tasa de Falsos Negativos**: < 5%
- **Precisi√≥n General**: > 95%

### **M√©tricas de Seguridad:**
- **Tiempo de Detecci√≥n**: < 1 segundo
- **Cobertura de Ataques**: 9 tipos principales
- **Disponibilidad**: 99.9%

### **Comparaci√≥n de Modelos:**
| M√©trica | Decision Trees | XGBoost | Enfoque H√≠brido |
|---------|---------------|---------|-----------------|
| **Precisi√≥n** | 85% | 98% | 96% |
| **Recall** | 80% | 95% | 92% |
| **F1-Score** | 82% | 96% | 94% |
| **Interpretabilidad** | 100% | 0% | 90% |
| **Tiempo de Explicaci√≥n** | 0ms | 500ms | 100ms |
| **Confianza del Usuario** | Alta | Baja | Alta |

---

## üéì **Beneficios Principales**

1. **Detecci√≥n Precisa**: 98% de precisi√≥n en detecci√≥n de ataques
2. **Explicabilidad**: Entiendes por qu√© el sistema tom√≥ una decisi√≥n
3. **Adaptabilidad**: Se ajusta a las necesidades espec√≠ficas de tu organizaci√≥n
4. **Trazabilidad**: Registro completo de todas las acciones
5. **Respuesta R√°pida**: Acciones autom√°ticas con supervisi√≥n humana
6. **Privacidad**: Procesamiento local, datos seguros

---

## üîÆ **Futuras Mejoras**

### **Pr√≥ximos Pasos:**
1. **Integraci√≥n de LIME**: M√©todo adicional de explicabilidad local
2. **Visualizaciones avanzadas**: Gr√°ficos interactivos con D3.js
3. **Explicaciones en tiempo real**: Streaming de explicaciones
4. **Aprendizaje federado**: Mejora de modelos con datos de m√∫ltiples organizaciones
5. **Explicaciones multiling√ºes**: Soporte para diferentes idiomas

### **Investigaci√≥n en Curso:**
- **Explicabilidad causal**: Entender relaciones causa-efecto
- **Explicaciones contrafactuales**: "¬øQu√© cambiar√≠a la decisi√≥n?"
- **Explicabilidad temporal**: C√≥mo cambian las explicaciones en el tiempo
- **Explicaciones colaborativas**: M√∫ltiples modelos explicando juntos

---

## üìû **Contacto**

**Proyecto:** Intrusion.Aware  
**Instituci√≥n:** Universidad Adolfo Ib√°√±ez  
**Financiamiento:** FONDEF-ANID  
**Asignatura:** TICS00866 - Auditor√≠a y Defensa en Sistemas de Inteligencia Artificial

---

## üìö **Referencias**

- [OWASP Machine Learning Security Top 10](https://github.com/owasp/www-project-machine-learning-security-top-10)
- [OWASP ML Top 10 PDF](https://mltop10.info/OWASP-Machine-Learning-Security-Top-10.pdf)
- [OWASP AI Security and Privacy Guide](https://owasp.org/www-project-ai-security-and-privacy-guide/)
- [Ejemplos Pr√°cticos de Vulnerabilidades ML](https://www.getastra.com/blog/security-audit/owasp-machine-learning-top-10/)
- [Adversarial Robustness Toolbox](https://github.com/Trusted-AI/adversarial-robustness-toolbox)
- [CleverHans Library](https://github.com/cleverhans-lab/cleverhans)
- [NIST AI Risk Management Framework](https://www.nist.gov/ai/risk-management)
- [UXAI.design](https://www.uxai.design) - Framework para dise√±o de interfaces explicables
- [UNSW-NB15 Dataset](https://research.unsw.edu.au/projects/unsw-nb15-dataset)

---

**"Protegiendo organizaciones con inteligencia artificial explicable"** üõ°Ô∏èü§ñ

---

## üìÅ **Archivos Detallados Disponibles**

Para informaci√≥n m√°s t√©cnica y detallada, consulta los siguientes archivos en la carpeta `detalles/`:

- `analisis-vulnerabilidades-ml.md` - An√°lisis detallado de vulnerabilidades ML
- `descripcion.md` - Descripci√≥n t√©cnica completa del sistema
- `enfoque-hibrido-explicabilidad.md` - Detalles sobre explicabilidad
- `explicacion-simple-sistema.md` - Explicaci√≥n paso a paso del funcionamiento
- `caracteristicas-dataset-tipos-ataques.md` - An√°lisis detallado del dataset y ataques
- `worm-simulation.sh` - Script de simulaci√≥n de gusanos para pruebas
